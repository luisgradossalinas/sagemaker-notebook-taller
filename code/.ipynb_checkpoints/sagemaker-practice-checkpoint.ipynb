{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation with Step Functions\n",
    "\n",
    "Ahora que tenemos nuestro proyecto de ciencia de datos construido, queremos implementarlo de una manera sólida y repetible. Para esto, implementaremos el ETL usando AWS Glue, y luego entrenaremos y transformaremos por lotes la entrada usando la integración de SageMaker con Amazon Step Functions.\n",
    "\n",
    "Este cuaderno lo guiará a través de este proceso paso a paso.\n",
    "\n",
    "Pero primero debe crear o configurar su propio cubo. El SDK de SageMaker es una buena forma de empezar.\n",
    "\n",
    "## 1. Subiendo archivos al bucket S3 external"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = sagemaker.Session()\n",
    "#your_bucket = ses.default_bucket()\n",
    "bucket = \"fashionstore-datalake-external-\" + str(account_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join('data','billing', 'billing_sm.csv')).upload_file('../data/billing_sm.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join('data','reseller', 'reseller_sm.csv')).upload_file('../data/reseller_sm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creando un Crawler en Glue (creará 2 tablas en el esquema external)\n",
    "\n",
    "Para usar esta información csv en el contexto de un ETL de Glue, primero tenemos que crear un rastreador de Glue que apunte a la ubicación de cada archivo. El rastreador intentará averiguar los tipos de datos de cada columna. La forma más segura de realizar este proceso es crear un rastreador para cada tabla que apunte a una ubicación diferente.\n",
    "\n",
    "Accederemos a Glue a la opción Crawler.\n",
    "Clic el enlace <a href='https://us-east-1.console.aws.amazon.com/glue/home?region=us-east-1#/v2/data-catalog/crawlers'> Link </a>       \n",
    "\n",
    "Clic en Create crawler.\n",
    "\n",
    "Asignamos el siguiente nombre : data_external y Next.\n",
    "\n",
    "<img src='img/c1.png' style='width:500px' />\n",
    "\n",
    "Clic en la opción Add a data source.\n",
    "\n",
    "<img src='img/c2.png' style='width:500px' />\n",
    "\n",
    "Seleccionamos la opción <br>\n",
    "Data Source : S3 <br>\n",
    "S3 Path ingresamos : **s3://fashionstore-datalake-external-TUACCOUNTID/data/**\n",
    "\n",
    "Clic en Add an S3 data source.\n",
    "\n",
    "<img src='img/c3.png' style='width:300px' />\n",
    "\n",
    "Clic en Next.\n",
    "\n",
    "<img src='img/c4.png' style='width:500px' />\n",
    "\n",
    "Seleccionamos el rol : RoleGlue-fashionstore y clic en Next.\n",
    "\n",
    "<img src='img/c5.png' style='width:500px' />\n",
    "\n",
    "Seleccionamos el esquema donde se van a crear las tablas : fashion_external.\n",
    "\n",
    "<img src='img/c6.png' style='width:500px' />\n",
    "\n",
    "Clic en Create crawler.\n",
    "\n",
    "<img src='img/c7.png' style='width:500px' />\n",
    "\n",
    "Seleccionamos el crawler creado y clic en la opción Run.\n",
    "\n",
    "<img src='img/c8.png' style='width:500px' />\n",
    "\n",
    "<img src='img/c9.png' style='width:500px' />\n",
    "\n",
    "Después de un minuto, se deben haber creado 2 tablas en el esquema fashion_external.\n",
    "\n",
    "<img src='img/c10.png' style='width:500px' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Glue Job\n",
    "\n",
    "First of all, you need to create a role to run the Glue Job. For simplicity we are going to build a role that can be assumed by the Glue Service with administrator access. \n",
    "\n",
    "In the <a href='https://console.aws.amazon.com/athena/home?region=us-east-1#'> IAM Console </a>\n",
    "\n",
    "* Under use case select Glue\n",
    "* Under Policies Select Administrator Access\n",
    "* Name your role GlueAdmin and accept.\n",
    "\n",
    "<img src='img/gluerole1.png' style='width:500px'>\n",
    "<img src='img/gluerole2.png' style='width:500px'>\n",
    "<img src='img/gluerole3.png' style='width:500px'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now move to the <a href='https://us-east-1.console.aws.amazon.com/gluestudio/home?region=us-east-1#/jobs'> Glue Job Console </a> and author a new job.\n",
    "\n",
    "Seleccionar : Spark script editor y clic en Create.\n",
    "\n",
    "<img src='img/c11.png' style='width:700px' />\n",
    "\n",
    "Asignamos el nombre al job : ETL_PIPELINE\n",
    "Y pegamos el contenido el código : ETL_PIPELINE.py\n",
    "\n",
    "<img src='img/c12.png' style='width:700px' />\n",
    "\n",
    "Clic en Job details y seleccionamos el rol : RoleGlue-fashionstore, y clic en Save.\n",
    "\n",
    "<img src='img/c13.png' style='width:700px' />    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create the Step Function\n",
    "\n",
    "First you need to create a role that can be assumed by AWS Step Functions and have enough permissions to create and use for inference SageMaker models and run Glue Jobs. \n",
    "First, we are going to create a role that can be assumed by the service Step Functions and then we are going to modify it to add Administrator Access. You can name this role StepFunctionsAdmin\n",
    "\n",
    "\n",
    "<img src='img/iamstep.png' />\n",
    "\n",
    "Tip: In this particular case it can not be done in the same step.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Next go to the <a href='https://console.aws.amazon.com/states/home?region=us-east-1#/statemachines'> Step Functions </a> console and create a new State Machine.\n",
    "\n",
    "* Author with code snippets\n",
    "* Standard\n",
    "\n",
    "\n",
    "In the json place you can use the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "your_role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Comment\": \"Full ML Pipeline\",\n",
      "  \"StartAt\": \"Start Glue Job\",\n",
      "  \"States\": {\n",
      "    \"Start Glue Job\": {\n",
      "      \"Type\": \"Task\",\n",
      "      \"Resource\": \"arn:aws:states:::glue:startJobRun.sync\",\n",
      "      \"Parameters\": {\n",
      "        \"JobName\": \"etlandpipeline\"\n",
      "      },\n",
      "      \"Next\": \"Train model (XGBoost)\"\n",
      "    },\n",
      "    \"Train model (XGBoost)\": {\n",
      "      \"Resource\": \"arn:aws:states:::sagemaker:createTrainingJob.sync\",\n",
      "      \"Parameters\": {\n",
      "        \"AlgorithmSpecification\": {\n",
      "          \"TrainingImage\": \"811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest\",\n",
      "          \"TrainingInputMode\": \"File\"\n",
      "        },\n",
      "        \"OutputDataConfig\": {\n",
      "          \"S3OutputPath\": \"s3://sagemaker-us-east-1-646862220717/models\"\n",
      "        },\n",
      "        \"StoppingCondition\": {\n",
      "          \"MaxRuntimeInSeconds\": 86400\n",
      "        },\n",
      "        \"ResourceConfig\": {\n",
      "          \"InstanceCount\": 1,\n",
      "          \"InstanceType\": \"ml.m4.xlarge\",\n",
      "          \"VolumeSizeInGB\": 30\n",
      "        },\n",
      "        \"RoleArn\": \"arn:aws:iam::646862220717:role/TeamRole\",\n",
      "        \"InputDataConfig\": [\n",
      "          {\n",
      "            \"DataSource\": {\n",
      "              \"S3DataSource\": {\n",
      "                \"S3DataDistributionType\": \"ShardedByS3Key\",\n",
      "                \"S3DataType\": \"S3Prefix\",\n",
      "                \"S3Uri\": \"s3://sagemaker-us-east-1-646862220717/train/train.csv\"\n",
      "              }\n",
      "            },\n",
      "            \"ChannelName\": \"train\",\n",
      "            \"ContentType\": \"text/csv\"\n",
      "          },\n",
      "          {\n",
      "            \"DataSource\": {\n",
      "              \"S3DataSource\": {\n",
      "                \"S3DataDistributionType\": \"ShardedByS3Key\",\n",
      "                \"S3DataType\": \"S3Prefix\",\n",
      "                \"S3Uri\": \"s3://sagemaker-us-east-1-646862220717/validation/validation.csv\"\n",
      "              }\n",
      "            },\n",
      "            \"ChannelName\": \"validation\",\n",
      "            \"ContentType\": \"text/csv\"\n",
      "          }\n",
      "        ],\n",
      "        \"HyperParameters\": {\n",
      "          \"objective\": \"reg:linear\",\n",
      "          \"num_round\": \"100\",\n",
      "          \"subsample\": \"0.7\",\n",
      "          \"eval_metric\": \"mae\"\n",
      "        },\n",
      "        \"TrainingJobName.$\": \"$$.Execution.Name\"\n",
      "      },\n",
      "      \"Type\": \"Task\",\n",
      "      \"Next\": \"Save Model\"\n",
      "    },\n",
      "    \"Save Model\": {\n",
      "      \"Parameters\": {\n",
      "        \"PrimaryContainer\": {\n",
      "          \"Image\": \"811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest\",\n",
      "          \"Environment\": {},\n",
      "          \"ModelDataUrl.$\": \"$.ModelArtifacts.S3ModelArtifacts\"\n",
      "        },\n",
      "        \"ExecutionRoleArn\": \"arn:aws:iam::646862220717:role/TeamRole\",\n",
      "        \"ModelName.$\": \"$.TrainingJobName\"\n",
      "      },\n",
      "      \"Resource\": \"arn:aws:states:::sagemaker:createModel\",\n",
      "      \"Type\": \"Task\",\n",
      "      \"Next\": \"Batch transform\"\n",
      "    },\n",
      "    \"Batch transform\": {\n",
      "      \"Type\": \"Task\",\n",
      "      \"Resource\": \"arn:aws:states:::sagemaker:createTransformJob.sync\",\n",
      "      \"Parameters\": {\n",
      "        \"ModelName.$\": \"$$.Execution.Name\",\n",
      "        \"TransformInput\": {\n",
      "          \"CompressionType\": \"None\",\n",
      "          \"ContentType\": \"text/csv\",\n",
      "          \"DataSource\": {\n",
      "            \"S3DataSource\": {\n",
      "              \"S3DataType\": \"S3Prefix\",\n",
      "              \"S3Uri\": \"s3://sagemaker-us-east-1-646862220717/to_predict.csv\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"TransformOutput\": {\n",
      "          \"S3OutputPath\": \"s3://sagemaker-us-east-1-646862220717/predictions\"\n",
      "        },\n",
      "        \"TransformResources\": {\n",
      "          \"InstanceCount\": 1,\n",
      "          \"InstanceType\": \"ml.m4.xlarge\"\n",
      "        },\n",
      "        \"TransformJobName.$\": \"$$.Execution.Name\"\n",
      "      },\n",
      "      \"End\": true\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "definition = open('step_function.json', 'r').read().replace('your_bucket',your_bucket).replace('your_role',your_role)\n",
    "print(definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the role that you previously created and then you can create and run your state machine. \n",
    "\n",
    "\n",
    "As you process starts running and moves thorugh each step you will be able to see the process running in each servicés console. \n",
    "\n",
    "Check <a href='https://console.aws.amazon.com/glue/home?region=us-east-1#etl:tab=jobs'> Glue </a> for job logs and\n",
    "<a href='https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/jobs'> SageMaker </a> to see the training job, the model that you created and the batch transform process. \n",
    "\n",
    "After you step function finishes the execution, you should see the graph turning to green:\n",
    "\n",
    "<img src='img/step.png' style='width:500px' />\n",
    "\n",
    "You can inspect your predictions in the predictinos folder on you bucket checking <a href='https://s3.console.aws.amazon.com/s3/home?region=us-east-1'>S3</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
